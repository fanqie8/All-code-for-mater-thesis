{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c26ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from scipy import sparse\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score,cross_validate, KFold\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_curve, auc, classification_report,accuracy_score,precision_score,f1_score,recall_score,cohen_kappa_score,multilabel_confusion_matrix,make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9e659a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT_NEW</th>\n",
       "      <th>WORDCUT</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>LEVEL</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>level1_tokens</th>\n",
       "      <th>level2_tokens</th>\n",
       "      <th>level3_tokens</th>\n",
       "      <th>level4_tokens</th>\n",
       "      <th>level5_tokens</th>\n",
       "      <th>level6_tokens</th>\n",
       "      <th>level7_tokens</th>\n",
       "      <th>char_num</th>\n",
       "      <th>high_level</th>\n",
       "      <th>primary_level</th>\n",
       "      <th>Connective_ratio</th>\n",
       "      <th>connective_SCORE</th>\n",
       "      <th>pre</th>\n",
       "      <th>connective_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>记得当年年纪小，家中兄弟姐妹数十多人。我排行倒最第二。父母亲为了养起这头家，日夜往外奔波劳累...</td>\n",
       "      <td>记得 当年 年纪 小 ， 家中 兄弟姐妹 数十 多人 。 我 排行 倒 最 第二 。 父母亲...</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>636</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.067251</td>\n",
       "      <td>2.984263</td>\n",
       "      <td>记得 当年 年纪 小 家中 兄弟姐妹 数十 多人 我 排行 倒 最 第二 父母亲 为了 养起...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>《一封求职信》×××揭阳县西门外磐东镇肇沟乡广东省李文先生快乐家庭旅游公司负责人广东省李文先...</td>\n",
       "      <td>《 一封 求职信 》 × × × 揭阳县 西 门外 磐 东镇肇沟 乡 广东省 李文 先生 快...</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>403</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>2.434391</td>\n",
       "      <td>一封 求职信 揭阳县 西 门外 磐 东镇肇沟 乡 广东省 李文 先生 快乐 家庭 旅游 公司...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我的外婆对我的影响非常大。从小，我父母便将我交给外婆带。他们是上班一族，平日无法照顾我。虽然...</td>\n",
       "      <td>我 的 外婆 对 我 的 影响 非常 大 。 从小 ， 我 父母 便 将 我 交给 外婆 带...</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>570</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>3.791400</td>\n",
       "      <td>我 的 外婆 对 我 的 影响 非常 大 从小 我 父母 便 将 我 交给 外婆 带 他们 ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“安乐死”究竟可不可取？在二十世纪的今天，“安乐死”已不是什么新话题。在不同的国家，已曾有人...</td>\n",
       "      <td>“ 安乐死 ” 究竟 可不 可取 ？ 在 二十世纪 的 今天 ， “ 安乐死 ” 已 不是 ...</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>588</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.084249</td>\n",
       "      <td>3.982972</td>\n",
       "      <td>安乐死 究竟 可不 可取 在 二十世纪 的 今天 安乐死 已 不是 什么 新 话题 在 不同...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>关于安乐死这个问题，近来引起了广泛的讨论，有些人认为：一个人既既身罹不治之症，与其留在世上饱...</td>\n",
       "      <td>关于 安乐死 这个 问题 ， 近来 引起 了 广泛 的 讨论 ， 有些 人 认为 ： 一个 ...</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>364</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>2.989940</td>\n",
       "      <td>关于 安乐死 这个 问题 近来 引起 了 广泛 的 讨论 有些 人 认为 一个 人 既 既身...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         CONTENT_NEW  \\\n",
       "0  记得当年年纪小，家中兄弟姐妹数十多人。我排行倒最第二。父母亲为了养起这头家，日夜往外奔波劳累...   \n",
       "1  《一封求职信》×××揭阳县西门外磐东镇肇沟乡广东省李文先生快乐家庭旅游公司负责人广东省李文先...   \n",
       "2  我的外婆对我的影响非常大。从小，我父母便将我交给外婆带。他们是上班一族，平日无法照顾我。虽然...   \n",
       "3  “安乐死”究竟可不可取？在二十世纪的今天，“安乐死”已不是什么新话题。在不同的国家，已曾有人...   \n",
       "4  关于安乐死这个问题，近来引起了广泛的讨论，有些人认为：一个人既既身罹不治之症，与其留在世上饱...   \n",
       "\n",
       "                                             WORDCUT  SCORE  LEVEL  Tokens  \\\n",
       "0  记得 当年 年纪 小 ， 家中 兄弟姐妹 数十 多人 。 我 排行 倒 最 第二 。 父母亲...     90      3     342   \n",
       "1  《 一封 求职信 》 × × × 揭阳县 西 门外 磐 东镇肇沟 乡 广东省 李文 先生 快...     80      3     194   \n",
       "2  我 的 外婆 对 我 的 影响 非常 大 。 从小 ， 我 父母 便 将 我 交给 外婆 带...     80      3     302   \n",
       "3  “ 安乐死 ” 究竟 可不 可取 ？ 在 二十世纪 的 今天 ， “ 安乐死 ” 已 不是 ...     95      3     273   \n",
       "4  关于 安乐死 这个 问题 ， 近来 引起 了 广泛 的 讨论 ， 有些 人 认为 ： 一个 ...     85      3     186   \n",
       "\n",
       "   level1_tokens  level2_tokens  level3_tokens  level4_tokens  level5_tokens  \\\n",
       "0              0              2              7              4              2   \n",
       "1              0              0              0              3              0   \n",
       "2              0              4              5              5              3   \n",
       "3              1              0              4              3              1   \n",
       "4              1              1              5              4              1   \n",
       "\n",
       "   level6_tokens  level7_tokens  char_num  high_level  primary_level  \\\n",
       "0              0              3       636           5             13   \n",
       "1              0              5       403           5              3   \n",
       "2              0              4       570           7             14   \n",
       "3              1              8       588          10              8   \n",
       "4              0              4       364           5             11   \n",
       "\n",
       "   Connective_ratio  connective_SCORE  \\\n",
       "0          0.067251          2.984263   \n",
       "1          0.051546          2.434391   \n",
       "2          0.072848          3.791400   \n",
       "3          0.084249          3.982972   \n",
       "4          0.096774          2.989940   \n",
       "\n",
       "                                                 pre  connective_numbers  \n",
       "0  记得 当年 年纪 小 家中 兄弟姐妹 数十 多人 我 排行 倒 最 第二 父母亲 为了 养起...                  23  \n",
       "1  一封 求职信 揭阳县 西 门外 磐 东镇肇沟 乡 广东省 李文 先生 快乐 家庭 旅游 公司...                  10  \n",
       "2  我 的 外婆 对 我 的 影响 非常 大 从小 我 父母 便 将 我 交给 外婆 带 他们 ...                  22  \n",
       "3  安乐死 究竟 可不 可取 在 二十世纪 的 今天 安乐死 已 不是 什么 新 话题 在 不同...                  23  \n",
       "4  关于 安乐死 这个 问题 近来 引起 了 广泛 的 讨论 有些 人 认为 一个 人 既 既身...                  18  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "dataframe = pd.read_csv(r'C:\\Users\\dawns\\Desktop\\Master thesis\\data\\Features_level.csv')\n",
    "#data=dataframe[['CONTENT_NEW','','SCORE']].copy()\n",
    "df_data=dataframe[['CONTENT_NEW','WORDCUT','SCORE','LEVEL','Tokens','level1_tokens','level2_tokens','level3_tokens','level4_tokens','level5_tokens','level6_tokens','level7_tokens','char_num','high_level','primary_level','Connective_ratio','connective_SCORE','pre','connective_numbers']].copy()\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e3a3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 'y' for classification as well as regression\n",
    "y = df_data['SCORE']\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e6f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating x \n",
    "pre = df_data['pre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a41742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3668,)\n",
      "(3668, 36035)\n"
     ]
    }
   ],
   "source": [
    "#TFIDF Vectorizer\n",
    "print(pre.shape)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(pre)\n",
    "vector = vectorizer.transform(pre)\n",
    "print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7374123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "#保存tf-idf特征 save tf-idf features\n",
    "print(type(vector))\n",
    "\n",
    "# save your model in disk\n",
    "joblib.dump(vector, 'vector.pkl') \n",
    "\n",
    "# load your model\n",
    "vector = joblib.load('vector.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f4d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3668, 1)\n",
      "(3668, 36035)\n",
      "=============\n",
      "(3668, 36036)\n"
     ]
    }
   ],
   "source": [
    "# 特征合并 feature concatenate \n",
    "feature_set1 = df_data[['connective_SCORE',]]\n",
    "feature_set2 = vector\n",
    "print(feature_set1.shape)\n",
    "print(feature_set2.shape)\n",
    "train_features = sparse.hstack((feature_set2, feature_set1))\n",
    "print('=============')\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed5e4e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2934, 36036)\n",
      "(2934,)\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集 ，测试集 train_test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_features, y, test_size=0.2)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c02f836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation \n",
    "\n",
    "def evaluation_scores(yt,yp):\n",
    "    MSE = mean_squared_error(yt,yp)\n",
    "    MAE = mean_absolute_error(yt,yp)\n",
    "    R2 = r2_score(yt,yp)\n",
    "    print('MSE:',MSE)\n",
    "    print(\"================================================\")\n",
    "    print('MAE:',MAE)\n",
    "    print(\"================================================\")\n",
    "    print('R2:',R2)\n",
    "    print(\"================================================\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e4447ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_mean_absolute_error: 7.395927744592785\n",
      "neg_mean_squared_error: 89.72646613093579\n",
      "r2: 0.3485797951795919\n"
     ]
    }
   ],
   "source": [
    "# linear regression 线性回归\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(x_train, y_train)\n",
    "y_pred = linear_regressor.predict(x_test)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "neg_mean_absolute_error = mean_absolute_error(y_test,y_pred)\n",
    "neg_mean_squared_error = mean_squared_error(y_test,y_pred)\n",
    "print('neg_mean_absolute_error:',neg_mean_absolute_error)\n",
    "print('neg_mean_squared_error:',neg_mean_squared_error)\n",
    "print('r2:',r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1523075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    40.0\n",
      "dtype: float64\n",
      "0    95.0\n",
      "dtype: float64\n",
      "qwkappa:\n",
      " 0.5559152272281542\n"
     ]
    }
   ],
   "source": [
    "df= pd.DataFrame(y_pred)\n",
    "print(df.min())\n",
    "print(df.max())\n",
    "df[(df >= 95)]=95\n",
    "df[(df >= 90) & (df <95)]=90\n",
    "df[(df >= 85) & (df < 90)]=85\n",
    "df[(df >= 80) & (df < 85)]=80\n",
    "df[(df >= 75) & (df < 80)]=75\n",
    "df[(df >= 70) & (df < 75)]=70\n",
    "df[(df >= 65) & (df < 70)]=65\n",
    "df[(df >= 60) & (df < 65)]=60\n",
    "df[(df >= 55) & (df < 60)]=55\n",
    "df[(df >= 50) & (df < 55)]=50\n",
    "df[(df >= 45) & (df < 50)]=45\n",
    "df[ (df < 45)]=40\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a2cce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65., 65., 60., 80., 80., 65., 65., 70., 65., 70., 70., 65., 65.,\n",
       "       75., 65., 55., 65., 60., 70., 70., 65., 70., 70., 65., 80., 75.,\n",
       "       60., 65., 80., 60., 55., 75., 75., 85., 65., 65., 70., 75., 60.,\n",
       "       70., 75., 60., 55., 65., 60., 70., 70., 70., 60., 80., 60., 75.,\n",
       "       90., 70., 65., 80., 55., 65., 80., 65., 75., 60., 70., 70., 65.,\n",
       "       65., 65., 75., 90., 70., 65., 45., 75., 65., 65., 75., 70., 75.,\n",
       "       75., 75., 75., 80., 65., 60., 65., 55., 75., 75., 60., 80., 65.,\n",
       "       60., 75., 60., 85., 85., 60., 80., 45., 60., 70., 70., 80., 65.,\n",
       "       70., 75., 90., 85., 85., 70., 85., 80., 65., 60., 65., 65., 80.,\n",
       "       75., 70., 65., 75., 60., 65., 85., 65., 95., 75., 75., 55., 70.,\n",
       "       90., 70., 65., 70., 80., 55., 65., 75., 70., 85., 65., 80., 60.,\n",
       "       70., 55., 65., 55., 75., 70., 70., 70., 70., 80., 70., 85., 70.,\n",
       "       70., 90., 80., 60., 65., 75., 75., 65., 75., 70., 85., 65., 75.,\n",
       "       70., 75., 80., 40., 70., 85., 60., 70., 70., 65., 70., 75., 70.,\n",
       "       70., 55., 65., 75., 80., 75., 65., 70., 50., 55., 60., 80., 70.,\n",
       "       80., 75., 90., 70., 75., 65., 80., 70., 80., 65., 80., 65., 65.,\n",
       "       70., 65., 60., 75., 75., 60., 70., 85., 70., 65., 50., 75., 60.,\n",
       "       65., 80., 75., 65., 75., 65., 70., 80., 70., 60., 75., 65., 60.,\n",
       "       65., 75., 55., 70., 60., 70., 65., 80., 75., 70., 55., 70., 80.,\n",
       "       65., 65., 70., 75., 85., 80., 65., 75., 75., 70., 75., 65., 50.,\n",
       "       75., 70., 55., 60., 60., 70., 65., 55., 75., 75., 65., 65., 75.,\n",
       "       75., 75., 75., 70., 75., 65., 65., 65., 70., 75., 70., 70., 75.,\n",
       "       75., 70., 75., 85., 75., 60., 85., 60., 75., 70., 80., 60., 80.,\n",
       "       90., 70., 70., 75., 55., 65., 85., 65., 80., 80., 75., 55., 55.,\n",
       "       80., 50., 75., 80., 70., 65., 55., 65., 80., 55., 85., 65., 70.,\n",
       "       70., 80., 75., 60., 70., 60., 75., 65., 70., 65., 75., 55., 70.,\n",
       "       70., 60., 65., 85., 75., 75., 75., 80., 65., 70., 70., 60., 75.,\n",
       "       65., 75., 80., 70., 75., 55., 65., 65., 55., 70., 65., 85., 65.,\n",
       "       70., 65., 60., 65., 65., 75., 70., 55., 70., 80., 55., 55., 55.,\n",
       "       60., 65., 65., 70., 60., 85., 70., 55., 70., 70., 70., 60., 70.,\n",
       "       55., 70., 65., 55., 70., 85., 70., 70., 80., 65., 80., 70., 50.,\n",
       "       80., 75., 60., 70., 65., 70., 65., 75., 65., 70., 60., 75., 65.,\n",
       "       80., 75., 55., 75., 65., 70., 65., 70., 70., 80., 80., 65., 80.,\n",
       "       70., 60., 60., 75., 80., 65., 60., 75., 80., 70., 60., 70., 55.,\n",
       "       65., 70., 80., 60., 70., 55., 80., 70., 70., 70., 60., 70., 70.,\n",
       "       60., 60., 65., 70., 65., 55., 75., 60., 65., 80., 75., 65., 55.,\n",
       "       90., 75., 50., 70., 65., 75., 75., 70., 70., 85., 65., 85., 70.,\n",
       "       50., 65., 60., 75., 65., 70., 55., 55., 65., 50., 50., 80., 65.,\n",
       "       70., 95., 95., 75., 75., 65., 70., 70., 65., 65., 65., 65., 70.,\n",
       "       70., 75., 70., 60., 60., 70., 80., 55., 75., 75., 75., 60., 70.,\n",
       "       90., 70., 55., 85., 75., 70., 55., 80., 55., 75., 80., 60., 50.,\n",
       "       85., 55., 55., 60., 55., 75., 65., 70., 85., 75., 65., 85., 80.,\n",
       "       65., 65., 75., 70., 75., 65., 65., 75., 75., 60., 80., 80., 70.,\n",
       "       65., 70., 60., 75., 70., 70., 70., 70., 80., 75., 80., 75., 65.,\n",
       "       70., 65., 75., 55., 70., 80., 55., 80., 55., 60., 60., 60., 70.,\n",
       "       60., 80., 50., 85., 60., 70., 75., 90., 85., 70., 80., 85., 75.,\n",
       "       80., 75., 65., 70., 65., 70., 70., 70., 70., 65., 70., 55., 60.,\n",
       "       75., 70., 60., 65., 65., 70., 70., 75., 50., 80., 60., 70., 90.,\n",
       "       65., 75., 75., 70., 75., 65., 50., 80., 60., 60., 65., 55., 70.,\n",
       "       70., 80., 80., 70., 60., 60., 55., 60., 60., 65., 70., 70., 55.,\n",
       "       65., 60., 55., 65., 65., 70., 85., 55., 60., 50., 80., 70., 70.,\n",
       "       80., 60., 55., 65., 70., 60., 70., 70., 75., 75., 70., 65., 70.,\n",
       "       65., 65., 70., 70., 65., 70., 70., 65., 60., 80., 65., 65., 60.,\n",
       "       70., 65., 60., 70., 70., 55., 60., 70., 75., 55., 70., 80., 70.,\n",
       "       70., 70., 80., 65., 80., 65., 80., 65., 65., 70., 75., 80., 75.,\n",
       "       75., 65., 70., 75., 55., 65., 70., 60., 65., 65., 80., 80., 75.,\n",
       "       70., 80., 70., 60., 70., 70.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c606f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.39139739564769394\n",
      "mean_squared_error: 83.82877989127076\n",
      "mean_absolute_error: 7.160362332944077\n"
     ]
    }
   ],
   "source": [
    "# 随机森林 random forest\n",
    "\n",
    "rf = ensemble.RandomForestRegressor()\n",
    "params = {'n_estimators': [100], 'max_depth':[100], 'max_features':[10]}\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print('r2:',r2_score(y_test,y_pred))\n",
    "print('mean_squared_error:',mean_squared_error(y_test,y_pred))\n",
    "print('mean_absolute_error:',mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bec6e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    46.0\n",
      "dtype: float64\n",
      "0    89.45\n",
      "dtype: float64\n",
      "qwkappa:\n",
      " 0.5108049743600471\n"
     ]
    }
   ],
   "source": [
    "df= pd.DataFrame(y_pred)\n",
    "print(df.min())\n",
    "print(df.max())\n",
    "df[(df >= 95)]=95\n",
    "df[(df >= 90) & (df <95)]=90\n",
    "df[(df >= 85) & (df < 90)]=85\n",
    "df[(df >= 80) & (df < 85)]=80\n",
    "df[(df >= 75) & (df < 80)]=75\n",
    "df[(df >= 70) & (df < 75)]=70\n",
    "df[(df >= 65) & (df < 70)]=65\n",
    "df[(df >= 60) & (df < 65)]=60\n",
    "df[(df >= 55) & (df < 60)]=55\n",
    "df[(df >= 50) & (df < 55)]=50\n",
    "df[(df >= 45) & (df < 50)]=45\n",
    "df[ (df < 45)]=40\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46678916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.3977361405962314\n",
      "mean_squared_error: 77.31495054691794\n",
      "mean_absolute_error: 6.86582322081688\n"
     ]
    }
   ],
   "source": [
    "#xgboost  xgboost处理回归\n",
    "model = xgb.XGBRegressor()\n",
    "params = {'n_estimators': [160], 'learning_rate': [0.1]}\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print('R2:',r2_score(y_test,y_pred))\n",
    "print('mean_squared_error:',mean_squared_error(y_test,y_pred))\n",
    "print('mean_absolute_error:',mean_absolute_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d9309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    39.797722\n",
      "dtype: float32\n",
      "0    93.848564\n",
      "dtype: float32\n",
      "qwkappa:\n",
      " 0.5829622958198278\n"
     ]
    }
   ],
   "source": [
    "df= pd.DataFrame(y_pred)\n",
    "print(df.min())\n",
    "print(df.max())\n",
    "df[(df >= 95)]=95\n",
    "df[(df >= 90) & (df <95)]=90\n",
    "df[(df >= 85) & (df < 90)]=85\n",
    "df[(df >= 80) & (df < 85)]=80\n",
    "df[(df >= 75) & (df < 80)]=75\n",
    "df[(df >= 70) & (df < 75)]=70\n",
    "df[(df >= 65) & (df < 70)]=65\n",
    "df[(df >= 60) & (df < 65)]=60\n",
    "df[(df >= 55) & (df < 60)]=55\n",
    "df[(df >= 50) & (df < 55)]=50\n",
    "df[(df >= 45) & (df < 50)]=45\n",
    "df[ (df < 45)]=40\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1c25433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.26721891, 0.2437892 , 0.37174541, 0.29904049, 0.24336781,\n",
      "       0.30014323, 0.27656403, 0.22895645, 0.29417619, 0.36340902])]\n",
      "0.28884107301750395\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证 cross validation linear\n",
    "cv_scores =[]\n",
    "scores = cross_val_score(linear_regressor,x_train,y_train,cv=10,scoring='r2')\n",
    "cv_scores.append(scores)\n",
    "print(cv_scores)\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9e76fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.42580237, 0.41812314, 0.48111322, 0.36624081, 0.3784345 ,\n",
      "       0.34818323, 0.40298443, 0.35252459, 0.41582634, 0.3759022 ])]\n",
      "0.3965134837196277\n"
     ]
    }
   ],
   "source": [
    "# randomforest regressor\n",
    "cv_scores =[]\n",
    "scores = cross_val_score(rf,x_train,y_train,cv=10,scoring='r2')\n",
    "cv_scores.append(scores)\n",
    "print(cv_scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70fe97ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.41705144, 0.35340054, 0.46571556, 0.41242091, 0.35365548,\n",
      "       0.34951364, 0.32518356, 0.33000066, 0.37391405, 0.33973798])]\n",
      "0.3720593825358806\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "cv_scores =[]\n",
    "scores = cross_val_score(model,x_train,y_train,cv=10,scoring='r2')\n",
    "cv_scores.append(scores)\n",
    "print(cv_scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785528f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
