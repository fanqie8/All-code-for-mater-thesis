{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c3129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import roc_curve, auc, classification_report,accuracy_score,precision_score,f1_score,recall_score,cohen_kappa_score,multilabel_confusion_matrix,make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from scipy import sparse\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score,cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c01ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "dataframe = pd.read_csv(r'C:\\Users\\dawns\\Desktop\\Master thesis\\data\\Features_level.csv')\n",
    "#data=dataframe[['CONTENT_NEW','','SCORE']].copy()\n",
    "df_data=dataframe[['CONTENT_NEW','WORDCUT','SCORE','LEVEL','Tokens','level1_tokens','level2_tokens','level3_tokens','level4_tokens','level5_tokens','level6_tokens','level7_tokens','char_num','high_level','primary_level','Connective_ratio','connective_SCORE','pre','connective_numbers']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c3937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 'y' for classification as well as regression\n",
    "y = df_data['SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aac4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generating x \n",
    "pre = df_data['pre']\n",
    "# Tokenization\n",
    "def preprocessing_sentence(x):\n",
    "    words = jieba.cut(str(x).strip())\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042c426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3668,)\n",
      "(3668, 1000)\n"
     ]
    }
   ],
   "source": [
    "#ngrams Vectorizer\n",
    "print(pre.shape)\n",
    "cv = CountVectorizer(ngram_range=(1, 3), max_features=1000)\n",
    "ngram_vector = cv.fit_transform(pre)\n",
    "print(ngram_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506d6cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3668, 1)\n",
      "(3668, 1000)\n",
      "=============\n",
      "(3668, 1001)\n"
     ]
    }
   ],
   "source": [
    "# 特征合并 feature concatenate \n",
    "feature_set1 = df_data[['connective_SCORE',]]\n",
    "feature_set2 = ngram_vector\n",
    "print(feature_set1.shape)\n",
    "print(feature_set2.shape)\n",
    "train_features = sparse.hstack((feature_set2, feature_set1))\n",
    "print('=============')\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f0980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2934, 1000)\n",
      "(2934,)\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集 ，测试集 train_test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature_set2, y, test_size=0.2)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1f9b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9815950920245399\n",
      "================================================\n",
      "Test Accuracy: 0.20027247956403268\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.         0.         0.11111111 0.1875     0.20224719 0.16666667\n",
      " 0.30322581 0.16666667 0.15384615 0.16       0.22916667 0.2       ]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.4758248703316602\n",
      "================================================\n",
      "Weighted precision 0.203373097380379\n",
      "Weighted recall 0.20027247956403268\n",
      "Weighted f1-score 0.19924583323739337\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          40       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         7\n",
      "          50       0.11      0.11      0.11        18\n",
      "          55       0.19      0.11      0.13        57\n",
      "          60       0.20      0.20      0.20        90\n",
      "          65       0.17      0.16      0.16        98\n",
      "          70       0.30      0.29      0.30       162\n",
      "          75       0.17      0.19      0.18        90\n",
      "          80       0.15      0.20      0.17        80\n",
      "          85       0.16      0.24      0.19        51\n",
      "          90       0.23      0.19      0.21        57\n",
      "          95       0.20      0.09      0.13        22\n",
      "\n",
      "    accuracy                           0.20       734\n",
      "   macro avg       0.16      0.15      0.15       734\n",
      "weighted avg       0.20      0.20      0.20       734\n",
      "\n",
      "================================================\n",
      "[[ 0  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  3  3  0  0  0  0  0  0  0]\n",
      " [ 0  1  2  1  7  6  0  0  1  0  0  0]\n",
      " [ 1  2  4  6 15  9 11  3  3  1  1  1]\n",
      " [ 0  0  2  6 18 17 18 12  7  6  2  2]\n",
      " [ 0  0  4  5 21 16 17  9 10 12  3  1]\n",
      " [ 0  0  0  5 14 23 47 27 30 12  4  0]\n",
      " [ 0  0  2  2  5  8 34 17 10  7  5  0]\n",
      " [ 0  0  1  2  4  9 16 16 16  9  6  1]\n",
      " [ 0  0  1  0  0  5  3 10  9 12 10  1]\n",
      " [ 0  0  0  2  1  2  7  7 15 10 11  2]\n",
      " [ 0  0  0  0  1  1  2  1  3  6  6  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Tf-IDF + LR \n",
    "#评估\n",
    "# （准确率、精确度、召回率、F1值、Kappa系数用于评估分类任务）\n",
    "## 二分类问题，一般设为两类，正类/反类，或0、1. 所以有tp，fn，fp，tn。 t，f代表是否正确，p，n代表是正类还是反类\n",
    "## 准确率（accuracy）：所有分类正确的样本数，除以样本总数）A= （tp+tn）/（tp+tn+fp+fn）\n",
    "## 精确度（precision）精确度也叫查准率，判为正的为p，包括正确tp，和错误fp，其中tp即预测正确的比例 P= tp/tp+fp\n",
    "## 召回率（recall） ： 查全率，判断正确的且为正的是tp，判断错误且为负（该正却负的），想知道tp占实际正确的比例 r= tp/tp+fn\n",
    "## f1 越大越好，f1=2*tp/(2*tp+fp+fn)\n",
    "## kappa 衡量分类精度，其计算基于混淆矩阵，目前用的是二次加权kappa，对错误的惩罚更重，应用更广泛\n",
    "# 逻辑回归LR\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "train_score = lr.score(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "y_pred = lr.predict(x_test)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb59503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.min())\n",
    "print(y_pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c6a80fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9996591683708248\n",
      "================================================\n",
      "Test Accuracy: 0.25885558583106266\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.         0.         0.         0.1        0.24590164 0.13934426\n",
      " 0.30097087 0.23529412 0.17948718 0.23333333 0.43478261 1.        ]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.3754489990136851\n",
      "================================================\n",
      "Weighted precision 0.25131092703291763\n",
      "Weighted recall 0.25885558583106266\n",
      "Weighted f1-score 0.2053450945073627\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          40       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         7\n",
      "          50       0.00      0.00      0.00        18\n",
      "          55       0.10      0.02      0.03        57\n",
      "          60       0.25      0.17      0.20        90\n",
      "          65       0.14      0.17      0.15        98\n",
      "          70       0.30      0.77      0.43       162\n",
      "          75       0.24      0.09      0.13        90\n",
      "          80       0.18      0.09      0.12        80\n",
      "          85       0.23      0.14      0.17        51\n",
      "          90       0.43      0.18      0.25        57\n",
      "          95       1.00      0.05      0.09        22\n",
      "\n",
      "    accuracy                           0.26       734\n",
      "   macro avg       0.24      0.14      0.13       734\n",
      "weighted avg       0.25      0.26      0.21       734\n",
      "\n",
      "================================================\n",
      "[[  0   0   0   0   0   1   1   0   0   0   0   0]\n",
      " [  0   0   0   3   1   3   0   0   0   0   0   0]\n",
      " [  0   0   0   1   4   4   8   0   1   0   0   0]\n",
      " [  1   0   1   1  12  13  25   2   0   2   0   0]\n",
      " [  0   0   0   1  15  20  50   1   2   1   0   0]\n",
      " [  0   0   0   1  14  17  51   7   6   1   1   0]\n",
      " [  0   0   0   1   8  21 124   4   2   1   1   0]\n",
      " [  0   0   0   0   1  14  60   8   4   2   1   0]\n",
      " [  0   0   0   1   6  13  41   3   7   4   5   0]\n",
      " [  0   0   0   0   0   6  22   4   9   7   3   0]\n",
      " [  0   0   0   0   0   7  25   0   6   9  10   0]\n",
      " [  0   0   0   1   0   3   5   5   2   3   2   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# randomforest classfier\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "params = {'n_estimators': [50], 'max_depth':[100], 'max_features':[10]}\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "train_score = rf.score(x_train, y_train)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b81aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.994546693933197\n",
      "================================================\n",
      "Test Accuracy: 0.25204359673024523\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.         0.2        0.         0.20833333 0.21794872 0.26190476\n",
      " 0.32432432 0.19402985 0.1509434  0.10204082 0.27272727 0.375     ]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.44188214503406875\n",
      "================================================\n",
      "Weighted precision 0.23111074423157604\n",
      "Weighted recall 0.25204359673024523\n",
      "Weighted f1-score 0.2279554996699112\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          40       0.00      0.00      0.00         2\n",
      "          45       0.20      0.14      0.17         7\n",
      "          50       0.00      0.00      0.00        18\n",
      "          55       0.21      0.09      0.12        57\n",
      "          60       0.22      0.19      0.20        90\n",
      "          65       0.26      0.22      0.24        98\n",
      "          70       0.32      0.59      0.42       162\n",
      "          75       0.19      0.14      0.17        90\n",
      "          80       0.15      0.10      0.12        80\n",
      "          85       0.10      0.10      0.10        51\n",
      "          90       0.27      0.26      0.27        57\n",
      "          95       0.38      0.14      0.20        22\n",
      "\n",
      "    accuracy                           0.25       734\n",
      "   macro avg       0.19      0.16      0.17       734\n",
      "weighted avg       0.23      0.25      0.23       734\n",
      "\n",
      "================================================\n",
      "[[ 0  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  2  1  0  1  0  1  0  0  0]\n",
      " [ 0  1  0  0  9  3  2  1  2  0  0  0]\n",
      " [ 1  1  1  5 17 12 14  0  2  2  1  1]\n",
      " [ 0  1  4  7 17 12 28  8  5  3  3  2]\n",
      " [ 0  0  2  5 10 22 36  5  7  5  5  1]\n",
      " [ 2  0  0  2 14 11 96 19  9  6  3  0]\n",
      " [ 0  0  2  2  3  8 49 13  3  4  6  0]\n",
      " [ 0  0  0  0  4  7 36 13  8  7  5  0]\n",
      " [ 0  0  1  0  2  3 16  3  7  5 14  0]\n",
      " [ 0  0  0  0  0  5 12  3  7 14 15  1]\n",
      " [ 0  0  0  1  1  1  6  2  2  3  3  3]]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine classfier\n",
    "model = OneVsRestClassifier(svm.SVC(kernel='rbf',gamma='scale'))#linear\n",
    "clt = model.fit(x_train,y_train)\n",
    "y_pred = clt.predict(x_test)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "train_score = clt.score(x_train, y_train)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1a902a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.95443892, 1.08485031, 0.96374011, 0.96272326, 0.96117592,\n",
      "       0.98288822, 0.93649101, 0.91806769, 0.9155252 , 0.90408349]), 'score_time': array([0.00299788, 0.0009985 , 0.00199962, 0.00243998, 0.00099969,\n",
      "       0.00102806, 0.00200105, 0.00200129, 0.00103092, 0.00202394]), 'test_accuracy': array([0.21428571, 0.20068027, 0.24829932, 0.2414966 , 0.21843003,\n",
      "       0.2116041 , 0.18771331, 0.20819113, 0.27986348, 0.22866894]), 'test_qwkappa': array([0.39728286, 0.36535368, 0.49203011, 0.47098105, 0.43014349,\n",
      "       0.41161763, 0.37080707, 0.37288367, 0.40451703, 0.48339454])}\n",
      "Mean accuracy: 0.22392328945229972\n",
      "Mean qwkappa: 0.41990111362235166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证 cross validation   logistic regression\n",
    "scoring = {'accuracy': 'accuracy','qwkappa': make_scorer(cohen_kappa_score,weights='quadratic')}\n",
    "scores = cross_validate(lr, x_train, y_train, cv=10, scoring=scoring)#10-fold cv\n",
    "accuracy = scores['test_accuracy']\n",
    "qwkappa = scores['test_qwkappa']\n",
    "print(scores)\n",
    "print('Mean accuracy:',accuracy.mean())\n",
    "print('Mean qwkappa:',qwkappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ea504b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([3.26331758, 3.14728093, 3.05274773, 3.05057573, 2.88794446,\n",
      "       2.93620825, 2.97148776, 2.97359633, 3.03866005, 3.01794744]), 'score_time': array([0.02467132, 0.02605987, 0.02403569, 0.02399993, 0.02299905,\n",
      "       0.02400088, 0.02200031, 0.02199864, 0.02400184, 0.02410269]), 'test_accuracy': array([0.2414966 , 0.24829932, 0.28231293, 0.28911565, 0.24232082,\n",
      "       0.24232082, 0.31740614, 0.25938567, 0.24914676, 0.27645051]), 'test_qwkappa': array([0.31101307, 0.39947035, 0.43605295, 0.4082973 , 0.37789486,\n",
      "       0.32096598, 0.48178678, 0.37020308, 0.35820806, 0.3516736 ])}\n",
      "Mean accuracy: 0.26482552065194676\n",
      "Mean qwkappa: 0.3815566030411007\n"
     ]
    }
   ],
   "source": [
    "# random forest classification\n",
    "scoring = {'accuracy': 'accuracy','qwkappa': make_scorer(cohen_kappa_score,weights='quadratic')}\n",
    "scores = cross_validate(rf, x_train, y_train, cv=10, scoring=scoring)#10-fold cv\n",
    "accuracy = scores['test_accuracy']\n",
    "qwkappa = scores['test_qwkappa']\n",
    "print(scores)\n",
    "print('Mean accuracy:',accuracy.mean())\n",
    "print('Mean qwkappa:',qwkappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "319a4d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([30.18462658, 31.71394444, 32.52860308, 29.70220089, 31.0586617 ,\n",
      "       31.11368322, 31.00566173, 28.450598  , 28.56923556, 28.38382649]), 'score_time': array([2.81480765, 3.39681315, 2.87610888, 2.86103988, 3.08868384,\n",
      "       3.08585882, 2.79151297, 2.83535552, 2.78470159, 2.78787589]), 'test_accuracy': array([0.25170068, 0.23129252, 0.27891156, 0.2585034 , 0.24232082,\n",
      "       0.2559727 , 0.25938567, 0.26962457, 0.3003413 , 0.26962457]), 'test_qwkappa': array([0.48737401, 0.44428811, 0.50995898, 0.5590035 , 0.45993222,\n",
      "       0.45003855, 0.45914817, 0.57997671, 0.51428812, 0.46167048])}\n",
      "Mean accuracy: 0.2617677787838685\n",
      "Mean qwkappa: 0.49256788464136214\n"
     ]
    }
   ],
   "source": [
    "# support machine classification\n",
    "scoring = {'accuracy': 'accuracy','qwkappa': make_scorer(cohen_kappa_score,weights='quadratic')}\n",
    "scores = cross_validate(clt, x_train, y_train, cv=10, scoring=scoring)#10-fold cv\n",
    "accuracy = scores['test_accuracy']\n",
    "qwkappa = scores['test_qwkappa']\n",
    "print(scores)\n",
    "print('Mean accuracy:',accuracy.mean())\n",
    "print('Mean qwkappa:',qwkappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf10f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
