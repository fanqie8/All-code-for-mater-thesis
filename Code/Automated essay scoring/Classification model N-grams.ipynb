{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c3129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import roc_curve, auc, classification_report,accuracy_score,precision_score,f1_score,recall_score,cohen_kappa_score,multilabel_confusion_matrix,make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from scipy import sparse\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score,cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c01ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT_NEW</th>\n",
       "      <th>WORDCUT</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>LEVEL</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>level1_tokens</th>\n",
       "      <th>level2_tokens</th>\n",
       "      <th>level3_tokens</th>\n",
       "      <th>level4_tokens</th>\n",
       "      <th>level5_tokens</th>\n",
       "      <th>level6_tokens</th>\n",
       "      <th>level7_tokens</th>\n",
       "      <th>char_num</th>\n",
       "      <th>high_level</th>\n",
       "      <th>primary_level</th>\n",
       "      <th>Connective_ratio</th>\n",
       "      <th>connective_SCORE</th>\n",
       "      <th>pre</th>\n",
       "      <th>connective_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>记得当年年纪小，家中兄弟姐妹数十多人。我排行倒最第二。父母亲为了养起这头家，日夜往外奔波劳累...</td>\n",
       "      <td>记得 当年 年纪 小 ， 家中 兄弟姐妹 数十 多人 。 我 排行 倒 最 第二 。 父母亲...</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>636</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.067251</td>\n",
       "      <td>2.984263</td>\n",
       "      <td>记得 当年 年纪 小 家中 兄弟姐妹 数十 多人 我 排行 倒 最 第二 父母亲 为了 养起...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>《一封求职信》×××揭阳县西门外磐东镇肇沟乡广东省李文先生快乐家庭旅游公司负责人广东省李文先...</td>\n",
       "      <td>《 一封 求职信 》 × × × 揭阳县 西 门外 磐 东镇肇沟 乡 广东省 李文 先生 快...</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>403</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>2.434391</td>\n",
       "      <td>一封 求职信 揭阳县 西 门外 磐 东镇肇沟 乡 广东省 李文 先生 快乐 家庭 旅游 公司...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我的外婆对我的影响非常大。从小，我父母便将我交给外婆带。他们是上班一族，平日无法照顾我。虽然...</td>\n",
       "      <td>我 的 外婆 对 我 的 影响 非常 大 。 从小 ， 我 父母 便 将 我 交给 外婆 带...</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>570</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>3.791400</td>\n",
       "      <td>我 的 外婆 对 我 的 影响 非常 大 从小 我 父母 便 将 我 交给 外婆 带 他们 ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“安乐死”究竟可不可取？在二十世纪的今天，“安乐死”已不是什么新话题。在不同的国家，已曾有人...</td>\n",
       "      <td>“ 安乐死 ” 究竟 可不 可取 ？ 在 二十世纪 的 今天 ， “ 安乐死 ” 已 不是 ...</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>588</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.084249</td>\n",
       "      <td>3.982972</td>\n",
       "      <td>安乐死 究竟 可不 可取 在 二十世纪 的 今天 安乐死 已 不是 什么 新 话题 在 不同...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>关于安乐死这个问题，近来引起了广泛的讨论，有些人认为：一个人既既身罹不治之症，与其留在世上饱...</td>\n",
       "      <td>关于 安乐死 这个 问题 ， 近来 引起 了 广泛 的 讨论 ， 有些 人 认为 ： 一个 ...</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>364</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>2.989940</td>\n",
       "      <td>关于 安乐死 这个 问题 近来 引起 了 广泛 的 讨论 有些 人 认为 一个 人 既 既身...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         CONTENT_NEW  \\\n",
       "0  记得当年年纪小，家中兄弟姐妹数十多人。我排行倒最第二。父母亲为了养起这头家，日夜往外奔波劳累...   \n",
       "1  《一封求职信》×××揭阳县西门外磐东镇肇沟乡广东省李文先生快乐家庭旅游公司负责人广东省李文先...   \n",
       "2  我的外婆对我的影响非常大。从小，我父母便将我交给外婆带。他们是上班一族，平日无法照顾我。虽然...   \n",
       "3  “安乐死”究竟可不可取？在二十世纪的今天，“安乐死”已不是什么新话题。在不同的国家，已曾有人...   \n",
       "4  关于安乐死这个问题，近来引起了广泛的讨论，有些人认为：一个人既既身罹不治之症，与其留在世上饱...   \n",
       "\n",
       "                                             WORDCUT  SCORE  LEVEL  Tokens  \\\n",
       "0  记得 当年 年纪 小 ， 家中 兄弟姐妹 数十 多人 。 我 排行 倒 最 第二 。 父母亲...     90      3     342   \n",
       "1  《 一封 求职信 》 × × × 揭阳县 西 门外 磐 东镇肇沟 乡 广东省 李文 先生 快...     80      3     194   \n",
       "2  我 的 外婆 对 我 的 影响 非常 大 。 从小 ， 我 父母 便 将 我 交给 外婆 带...     80      3     302   \n",
       "3  “ 安乐死 ” 究竟 可不 可取 ？ 在 二十世纪 的 今天 ， “ 安乐死 ” 已 不是 ...     95      3     273   \n",
       "4  关于 安乐死 这个 问题 ， 近来 引起 了 广泛 的 讨论 ， 有些 人 认为 ： 一个 ...     85      3     186   \n",
       "\n",
       "   level1_tokens  level2_tokens  level3_tokens  level4_tokens  level5_tokens  \\\n",
       "0              0              2              7              4              2   \n",
       "1              0              0              0              3              0   \n",
       "2              0              4              5              5              3   \n",
       "3              1              0              4              3              1   \n",
       "4              1              1              5              4              1   \n",
       "\n",
       "   level6_tokens  level7_tokens  char_num  high_level  primary_level  \\\n",
       "0              0              3       636           5             13   \n",
       "1              0              5       403           5              3   \n",
       "2              0              4       570           7             14   \n",
       "3              1              8       588          10              8   \n",
       "4              0              4       364           5             11   \n",
       "\n",
       "   Connective_ratio  connective_SCORE  \\\n",
       "0          0.067251          2.984263   \n",
       "1          0.051546          2.434391   \n",
       "2          0.072848          3.791400   \n",
       "3          0.084249          3.982972   \n",
       "4          0.096774          2.989940   \n",
       "\n",
       "                                                 pre  connective_numbers  \n",
       "0  记得 当年 年纪 小 家中 兄弟姐妹 数十 多人 我 排行 倒 最 第二 父母亲 为了 养起...                  23  \n",
       "1  一封 求职信 揭阳县 西 门外 磐 东镇肇沟 乡 广东省 李文 先生 快乐 家庭 旅游 公司...                  10  \n",
       "2  我 的 外婆 对 我 的 影响 非常 大 从小 我 父母 便 将 我 交给 外婆 带 他们 ...                  22  \n",
       "3  安乐死 究竟 可不 可取 在 二十世纪 的 今天 安乐死 已 不是 什么 新 话题 在 不同...                  23  \n",
       "4  关于 安乐死 这个 问题 近来 引起 了 广泛 的 讨论 有些 人 认为 一个 人 既 既身...                  18  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "dataframe = pd.read_csv(r'C:\\Users\\dawns\\Desktop\\Master thesis\\data\\Features_level.csv')\n",
    "#data=dataframe[['CONTENT_NEW','','SCORE']].copy()\n",
    "df_data=dataframe[['CONTENT_NEW','WORDCUT','SCORE','LEVEL','Tokens','level1_tokens','level2_tokens','level3_tokens','level4_tokens','level5_tokens','level6_tokens','level7_tokens','char_num','high_level','primary_level','Connective_ratio','connective_SCORE','pre','connective_numbers']].copy()\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c3937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 'y' for classification as well as regression\n",
    "y = df_data['SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aac4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generating x \n",
    "pre = df_data['pre']\n",
    "# Tokenization\n",
    "def preprocessing_sentence(x):\n",
    "    words = jieba.cut(str(x).strip())\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042c426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3668,)\n",
      "(3668, 1000)\n"
     ]
    }
   ],
   "source": [
    "#ngrams Vectorizer\n",
    "print(pre.shape)\n",
    "cv = CountVectorizer(ngram_range=(1, 3), max_features=1000)\n",
    "ngram_vector = cv.fit_transform(pre)\n",
    "print(ngram_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506d6cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3668, 1)\n",
      "(3668, 1000)\n",
      "=============\n",
      "(3668, 1001)\n"
     ]
    }
   ],
   "source": [
    "# 特征合并 feature concatenate \n",
    "feature_set1 = df_data[['connective_SCORE',]]\n",
    "feature_set2 = ngram_vector\n",
    "print(feature_set1.shape)\n",
    "print(feature_set2.shape)\n",
    "train_features = sparse.hstack((feature_set2, feature_set1))\n",
    "print('=============')\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f0980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2934, 1001)\n",
      "(2934,)\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集 ，测试集 train_test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_features, y, test_size=0.2)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1f9b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9713701431492843\n",
      "================================================\n",
      "Test Accuracy: 0.23024523160762944\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.         0.         0.         0.18181818 0.14736842 0.19444444\n",
      " 0.36       0.29090909 0.15       0.12121212 0.28070175 0.44444444]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.4934967994157322\n",
      "================================================\n",
      "Weighted precision 0.23077810950462607\n",
      "Weighted recall 0.23024523160762944\n",
      "Weighted f1-score 0.22764560457061417\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          40       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         9\n",
      "          50       0.00      0.00      0.00        20\n",
      "          55       0.18      0.17      0.17        48\n",
      "          60       0.15      0.16      0.16        85\n",
      "          65       0.19      0.22      0.21        95\n",
      "          70       0.36      0.34      0.35       157\n",
      "          75       0.29      0.31      0.30       104\n",
      "          80       0.15      0.16      0.15        77\n",
      "          85       0.12      0.12      0.12        65\n",
      "          90       0.28      0.36      0.32        44\n",
      "          95       0.44      0.16      0.24        25\n",
      "\n",
      "    accuracy                           0.23       734\n",
      "   macro avg       0.18      0.17      0.17       734\n",
      "weighted avg       0.23      0.23      0.23       734\n",
      "\n",
      "================================================\n",
      "[[ 0  0  0  1  2  2  0  0  0  0  0  0]\n",
      " [ 0  0  2  2  4  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  4  7  4  3  1  0  1  0  0]\n",
      " [ 0  1  4  8 10  8  6  5  4  1  1  0]\n",
      " [ 1  0  3 13 14 25  9 12  5  2  1  0]\n",
      " [ 0  0  3  4 19 21 13 15  9 10  1  0]\n",
      " [ 0  0  0  4 19 23 54 20 19 13  5  0]\n",
      " [ 0  0  0  3  7  9 31 32 11  5  6  0]\n",
      " [ 0  0  0  4  7  6 12 16 12 11  7  2]\n",
      " [ 0  0  1  0  3  5 17  5 11  8 14  1]\n",
      " [ 0  0  0  0  2  2  1  3  8 10 16  2]\n",
      " [ 0  0  0  1  1  3  4  1  1  4  6  4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Tf-IDF + LR \n",
    "#评估\n",
    "# （准确率、精确度、召回率、F1值、Kappa系数用于评估分类任务）\n",
    "## 二分类问题，一般设为两类，正类/反类，或0、1. 所以有tp，fn，fp，tn。 t，f代表是否正确，p，n代表是正类还是反类\n",
    "## 准确率（accuracy）：所有分类正确的样本数，除以样本总数）A= （tp+tn）/（tp+tn+fp+fn）\n",
    "## 精确度（precision）精确度也叫查准率，判为正的为p，包括正确tp，和错误fp，其中tp即预测正确的比例 P= tp/tp+fp\n",
    "## 召回率（recall） ： 查全率，判断正确的且为正的是tp，判断错误且为负（该正却负的），想知道tp占实际正确的比例 r= tp/tp+fn\n",
    "## f1 越大越好，f1=2*tp/(2*tp+fp+fn)\n",
    "## kappa 衡量分类精度，其计算基于混淆矩阵，目前用的是二次加权kappa，对错误的惩罚更重，应用更广泛\n",
    "# 逻辑回归LR\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "train_score = lr.score(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "y_pred = lr.predict(x_test)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c6a80fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9996591683708248\n",
      "================================================\n",
      "Test Accuracy: 0.2683923705722071\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.         0.         0.         0.08333333 0.29032258 0.20560748\n",
      " 0.2924282  0.32258065 0.26315789 0.21875    0.27272727 1.        ]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.4862810881842069\n",
      "================================================\n",
      "Weighted precision 0.2713237762680798\n",
      "Weighted recall 0.2683923705722071\n",
      "Weighted f1-score 0.22171465087295417\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          40       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         9\n",
      "          50       0.00      0.00      0.00        20\n",
      "          55       0.08      0.04      0.06        48\n",
      "          60       0.29      0.21      0.24        85\n",
      "          65       0.21      0.23      0.22        95\n",
      "          70       0.29      0.71      0.41       157\n",
      "          75       0.32      0.10      0.15       104\n",
      "          80       0.26      0.13      0.17        77\n",
      "          85       0.22      0.11      0.14        65\n",
      "          90       0.27      0.34      0.30        44\n",
      "          95       1.00      0.04      0.08        25\n",
      "\n",
      "    accuracy                           0.27       734\n",
      "   macro avg       0.25      0.16      0.15       734\n",
      "weighted avg       0.27      0.27      0.22       734\n",
      "\n",
      "================================================\n",
      "[[  0   0   0   3   1   1   0   0   0   0   0   0]\n",
      " [  0   0   0   2   5   2   0   0   0   0   0   0]\n",
      " [  0   0   0   4   3   4   8   0   1   0   0   0]\n",
      " [  0   0   0   2  11  15  18   0   0   1   1   0]\n",
      " [  0   0   0   5  18  20  37   3   1   1   0   0]\n",
      " [  0   0   0   3   8  22  52   1   3   2   4   0]\n",
      " [  0   0   0   2  11  18 112   4   5   3   2   0]\n",
      " [  0   0   0   0   2   9  70  10   1   5   7   0]\n",
      " [  0   0   1   0   2   7  38   6  10   6   7   0]\n",
      " [  0   0   0   1   1   5  30   4   6   7  11   0]\n",
      " [  0   0   0   1   0   2  14   1   7   4  15   0]\n",
      " [  0   0   0   1   0   2   4   2   4   3   8   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# randomforest classfier\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "params = {'n_estimators': [50], 'max_depth':[100], 'max_features':[10]}\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "train_score = rf.score(x_train, y_train)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b81aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9935241990456715\n",
      "================================================\n",
      "Test Accuracy: 0.25340599455040874\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.5        0.         0.         0.2        0.18181818 0.16470588\n",
      " 0.32624113 0.31034483 0.19607843 0.21428571 0.25       0.25      ]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.5234786953900823\n",
      "================================================\n",
      "Weighted precision 0.23565931218981803\n",
      "Weighted recall 0.25340599455040874\n",
      "Weighted f1-score 0.22980122574615647\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          40       0.50      0.40      0.44         5\n",
      "          45       0.00      0.00      0.00         9\n",
      "          50       0.00      0.00      0.00        20\n",
      "          55       0.20      0.17      0.18        48\n",
      "          60       0.18      0.16      0.17        85\n",
      "          65       0.16      0.15      0.16        95\n",
      "          70       0.33      0.59      0.42       157\n",
      "          75       0.31      0.17      0.22       104\n",
      "          80       0.20      0.13      0.16        77\n",
      "          85       0.21      0.18      0.20        65\n",
      "          90       0.25      0.34      0.29        44\n",
      "          95       0.25      0.04      0.07        25\n",
      "\n",
      "    accuracy                           0.25       734\n",
      "   macro avg       0.22      0.19      0.19       734\n",
      "weighted avg       0.24      0.25      0.23       734\n",
      "\n",
      "================================================\n",
      "[[ 2  1  0  1  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  1  3  4  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  7  5  3  2  2  1  0  0  0]\n",
      " [ 1  0  5  8 10  9 10  2  2  0  1  0]\n",
      " [ 1  1  2  8 14 26 19  2  4  6  2  0]\n",
      " [ 0  1  2  4 16 14 38 11  4  3  2  0]\n",
      " [ 0  0  2  5 17 10 92 12  9  6  4  0]\n",
      " [ 0  0  0  2  2  9 55 18  8  7  3  0]\n",
      " [ 0  0  1  1  5  6 25  5 10 10 14  0]\n",
      " [ 0  0  1  0  2  4 23  4  4 12 13  2]\n",
      " [ 0  0  0  0  0  2 11  1  7  7 15  1]\n",
      " [ 0  0  0  1  2  1  6  1  2  5  6  1]]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine classfier\n",
    "model = OneVsRestClassifier(svm.SVC(kernel='rbf',gamma='scale'))#linear\n",
    "clt = model.fit(x_train,y_train)\n",
    "y_pred = clt.predict(x_test)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "train_score = clt.score(x_train, y_train)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a902a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.77871847, 0.79944134, 0.76577067, 0.87449384, 0.82387185,\n",
      "       0.83175254, 0.84361839, 0.80493212, 0.8043108 , 0.92487311]), 'score_time': array([0.        , 0.        , 0.        , 0.        , 0.0009985 ,\n",
      "       0.        , 0.        , 0.        , 0.00099564, 0.00202537]), 'test_accuracy': array([0.21768707, 0.16666667, 0.19727891, 0.2244898 , 0.2116041 ,\n",
      "       0.17406143, 0.221843  , 0.20819113, 0.22525597, 0.21843003]), 'test_qwkappa': array([0.52614537, 0.40524777, 0.32262988, 0.49967206, 0.41504798,\n",
      "       0.41901953, 0.52382662, 0.42741474, 0.52167977, 0.5094864 ])}\n",
      "Mean accuracy: 0.2065508114508602\n",
      "Mean qwkappa: 0.4570170131881898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证 cross validation   logistic regression\n",
    "scoring = {'accuracy': 'accuracy','qwkappa': make_scorer(cohen_kappa_score,weights='quadratic')}\n",
    "scores = cross_validate(lr, x_train, y_train, cv=10, scoring=scoring)#10-fold cv\n",
    "accuracy = scores['test_accuracy']\n",
    "qwkappa = scores['test_qwkappa']\n",
    "print(scores)\n",
    "print('Mean accuracy:',accuracy.mean())\n",
    "print('Mean qwkappa:',qwkappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea504b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([3.05672026, 3.07450509, 2.79311776, 3.01151681, 2.70615125,\n",
      "       2.64042497, 2.89749503, 3.02075434, 3.00178528, 3.06069255]), 'score_time': array([0.03091598, 0.02029252, 0.02026272, 0.02393556, 0.01977897,\n",
      "       0.02026582, 0.02589798, 0.0201726 , 0.0202713 , 0.02490139]), 'test_accuracy': array([0.29251701, 0.24829932, 0.26530612, 0.25170068, 0.23208191,\n",
      "       0.2559727 , 0.25938567, 0.25938567, 0.28327645, 0.29692833]), 'test_qwkappa': array([0.48196464, 0.43946134, 0.44346973, 0.32160969, 0.44369278,\n",
      "       0.35327652, 0.41418287, 0.36000794, 0.50864665, 0.48154244])}\n",
      "Mean accuracy: 0.264485384597525\n",
      "Mean qwkappa: 0.42478546096395114\n"
     ]
    }
   ],
   "source": [
    "# random forest classification\n",
    "scoring = {'accuracy': 'accuracy','qwkappa': make_scorer(cohen_kappa_score,weights='quadratic')}\n",
    "scores = cross_validate(rf, x_train, y_train, cv=10, scoring=scoring)#10-fold cv\n",
    "accuracy = scores['test_accuracy']\n",
    "qwkappa = scores['test_qwkappa']\n",
    "print(scores)\n",
    "print('Mean accuracy:',accuracy.mean())\n",
    "print('Mean qwkappa:',qwkappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "319a4d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([27.02580047, 27.3972199 , 25.65024781, 26.38883996, 27.41537142,\n",
      "       28.87731266, 29.85189939, 28.37330413, 27.70096231, 28.80699205]), 'score_time': array([2.91128564, 2.72042584, 2.47179818, 2.69716477, 2.69400811,\n",
      "       2.96673727, 2.61925387, 2.69744706, 2.95669103, 2.5125854 ]), 'test_accuracy': array([0.29251701, 0.23469388, 0.2755102 , 0.30272109, 0.2559727 ,\n",
      "       0.25255973, 0.23890785, 0.27645051, 0.26962457, 0.27303754]), 'test_qwkappa': array([0.55288353, 0.48951593, 0.45071625, 0.50415805, 0.38741483,\n",
      "       0.46259721, 0.5043332 , 0.45905361, 0.58221772, 0.50886641])}\n",
      "Mean accuracy: 0.26719950778946394\n",
      "Mean qwkappa: 0.490175675557272\n"
     ]
    }
   ],
   "source": [
    "# support machine classification\n",
    "scoring = {'accuracy': 'accuracy','qwkappa': make_scorer(cohen_kappa_score,weights='quadratic')}\n",
    "scores = cross_validate(clt, x_train, y_train, cv=10, scoring=scoring)#10-fold cv\n",
    "accuracy = scores['test_accuracy']\n",
    "qwkappa = scores['test_qwkappa']\n",
    "print(scores)\n",
    "print('Mean accuracy:',accuracy.mean())\n",
    "print('Mean qwkappa:',qwkappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf10f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
