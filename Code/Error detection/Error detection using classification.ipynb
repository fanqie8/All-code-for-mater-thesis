{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cassis import load_typesystem, load_cas_from_xmi\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import roc_curve, auc, classification_report,accuracy_score,precision_score,f1_score,recall_score,cohen_kappa_score,multilabel_confusion_matrix,make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cas\n",
    "def load_cas(text_directory):\n",
    "    with open(text_directory+'/TypeSystem.xml', 'rb') as f:\n",
    "        typesystem = load_typesystem(f)\n",
    "    with open(text_directory+'/zhengwu.xmi', 'rb') as f:\n",
    "        cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "    return cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(r'C:\\Users\\dawns\\Desktop\\Master thesis\\data\\With connective error.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GreenFood_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GreenFood_100.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GreenFood_104.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GreenFood_110.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GreenFood_114.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>1625</td>\n",
       "      <td>Multi_981.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>1626</td>\n",
       "      <td>Multi_99.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>1627</td>\n",
       "      <td>Multi_994.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>1628</td>\n",
       "      <td>Multi_996.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>1629</td>\n",
       "      <td>Multi_998.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0              Title\n",
       "0              0    GreenFood_1.txt\n",
       "1              1  GreenFood_100.txt\n",
       "2              2  GreenFood_104.txt\n",
       "3              3  GreenFood_110.txt\n",
       "4              4  GreenFood_114.txt\n",
       "...          ...                ...\n",
       "1625        1625      Multi_981.txt\n",
       "1626        1626       Multi_99.txt\n",
       "1627        1627      Multi_994.txt\n",
       "1628        1628      Multi_996.txt\n",
       "1629        1629      Multi_998.txt\n",
       "\n",
       "[1630 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_list = dataframe['Title'].tolist()\n",
    "directory = r'C:\\Users\\dawns\\Desktop\\annotation\\annotation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence_list=[]\n",
    "location_list=[]\n",
    "type_list=[]\n",
    "error_list=[]\n",
    "for text in train_list:\n",
    "    text_dir = directory + '/' + text\n",
    "    cas = load_cas(text_dir)\n",
    "    for sentence in cas.select('de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence'):\n",
    "        sentence_list.append(sentence.get_covered_text())\n",
    "        location_list.append(sentence)\n",
    "    #print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sentence_list)\n",
    "df2=pd.DataFrame()\n",
    "df2['sentence']= pd.DataFrame(sentence_list)\n",
    "#print(location_list)\n",
    "df2['location_list']= pd.DataFrame(location_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>location_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25957</th>\n",
       "      <td>对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25958</th>\n",
       "      <td>学习汉语的乐处可真多。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25959</th>\n",
       "      <td>在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25960</th>\n",
       "      <td>和别人以汉语来交谈的亲切感等等。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25961</th>\n",
       "      <td>(101F)(155J)\"}</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=590, end=604)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0      [BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...   \n",
       "1      是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...   \n",
       "2                      “少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。   \n",
       "3              现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。   \n",
       "4                           但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？   \n",
       "...                                                  ...   \n",
       "25957  对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...   \n",
       "25958                                        学习汉语的乐处可真多。   \n",
       "25959                   在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。   \n",
       "25960                                   和别人以汉语来交谈的亲切感等等。   \n",
       "25961                                     (101F)(155J)\"}   \n",
       "\n",
       "                                      location_list  \n",
       "0         d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)  \n",
       "1       d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)  \n",
       "2      d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)  \n",
       "3      d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)  \n",
       "4      d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)  \n",
       "...                                             ...  \n",
       "25957  d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)  \n",
       "25958  d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)  \n",
       "25959  d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)  \n",
       "25960  d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)  \n",
       "25961  d.t.u.d.c.a.s.t.Sentence(begin=590, end=604)  \n",
       "\n",
       "[25962 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence_list=[]\n",
    "location_list=[]\n",
    "type_list=[]\n",
    "error_list=[]\n",
    "for text in train_list:\n",
    "    text_dir = directory + '/' + text\n",
    "    cas = load_cas(text_dir)\n",
    "    for sentence in cas.select('de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence'):\n",
    "        error = cas.select_covered('webanno.custom.Error', sentence)\n",
    "        if(len(error)>0):\n",
    "            type_list.append('1')\n",
    "            error_list.append(error[0].get_covered_text())\n",
    "        else:\n",
    "            type_list.append('0')\n",
    "            error_list.append('0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list\n",
    "df2['type_list']= pd.DataFrame(type_list)\n",
    "error_list\n",
    "df2['error_list']= pd.DataFrame(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>location_list</th>\n",
       "      <th>type_list</th>\n",
       "      <th>error_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25957</th>\n",
       "      <td>对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25958</th>\n",
       "      <td>学习汉语的乐处可真多。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25959</th>\n",
       "      <td>在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25960</th>\n",
       "      <td>和别人以汉语来交谈的亲切感等等。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25961</th>\n",
       "      <td>(101F)(155J)\"}</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=590, end=604)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0      [BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...   \n",
       "1      是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...   \n",
       "2                      “少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。   \n",
       "3              现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。   \n",
       "4                           但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？   \n",
       "...                                                  ...   \n",
       "25957  对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...   \n",
       "25958                                        学习汉语的乐处可真多。   \n",
       "25959                   在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。   \n",
       "25960                                   和别人以汉语来交谈的亲切感等等。   \n",
       "25961                                     (101F)(155J)\"}   \n",
       "\n",
       "                                      location_list type_list error_list  \n",
       "0         d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)         0          0  \n",
       "1       d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)         0          0  \n",
       "2      d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)         0          0  \n",
       "3      d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)         0          0  \n",
       "4      d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)         0          0  \n",
       "...                                             ...       ...        ...  \n",
       "25957  d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)         0          0  \n",
       "25958  d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)         0          0  \n",
       "25959  d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)         0          0  \n",
       "25960  d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)         0          0  \n",
       "25961  d.t.u.d.c.a.s.t.Sentence(begin=590, end=604)         0          0  \n",
       "\n",
       "[25962 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(r'C:\\Users\\dawns\\Desktop\\Master thesis\\data\\Error annotation dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we already build the dataset, then we can start here for loading the dataset directly\n",
    "df2 = pd.read_csv(r'C:\\Users\\dawns\\Desktop\\Master thesis\\data\\Error annotation dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    23537\n",
      "1     2425\n",
      "Name: type_list, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = df2.loc[:, 'type_list'].value_counts()\n",
    "count\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_sentence(x):\n",
    "    words = jieba.cut(str(x).strip())\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df2['sentence'], df2['type_list'], test_size=0.2)\n",
    "\n",
    "x_train = x_train.apply(lambda x: preprocessing_sentence(x))\n",
    "x_test = x_test.apply(lambda x: preprocessing_sentence(x))\n",
    "\n",
    "#TF-IDF\n",
    "tf = TfidfVectorizer()\n",
    "x_train = tf.fit_transform(x_train).toarray()\n",
    "x_test = tf.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20769, 17425)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9158361018826136\n",
      "================================================\n",
      "Test Accuracy: 0.9127671865973426\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.92145254 0.56349206]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.20837535548468578\n",
      "================================================\n",
      "Weighted precision 0.8891237353983864\n",
      "Weighted recall 0.9127671865973426\n",
      "Weighted f1-score 0.889151588448688\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      4724\n",
      "           1       0.56      0.15      0.24       469\n",
      "\n",
      "    accuracy                           0.91      5193\n",
      "   macro avg       0.74      0.57      0.60      5193\n",
      "weighted avg       0.89      0.91      0.89      5193\n",
      "\n",
      "================================================\n",
      "[[4669   55]\n",
      " [ 398   71]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "train_score = lr.score(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "y_pred = lr.predict(x_test)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([14.13101983, 14.78310657, 15.27889919, 13.91827226, 13.839077  ]), 'score_time': array([0.1319592 , 0.11776042, 0.11514306, 0.1160512 , 0.12700176]), 'test_recall': array([0.10230179, 0.1202046 , 0.10230179, 0.10714286, 0.10741688]), 'test_qwkappa': array([0.13524033, 0.16815066, 0.14921618, 0.15773269, 0.15119701])}\n",
      "Mean recall: 0.1078735842162952\n",
      "Mean qwkappa: 0.15230737362648566\n"
     ]
    }
   ],
   "source": [
    "scoring = {'recall': 'recall','qwkappa': make_scorer(cohen_kappa_score,weights='quadratic')}\n",
    "scores = cross_validate(lr, x_train, y_train, cv=5, scoring=scoring)#5-fold cv\n",
    "recall = scores['test_recall']\n",
    "qwkappa = scores['test_qwkappa']\n",
    "print(scores)\n",
    "print('Mean recall:',recall.mean())\n",
    "print('Mean qwkappa:',qwkappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04243176737848662\n",
      "RandomForestRegressor(max_depth=100, max_features=10)\n",
      "{'max_depth': 100, 'max_features': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestRegressor()\n",
    "params = {'n_estimators': [10, 50, 100], 'max_depth':[10, 50, 100], 'max_features':[2, 5, 10]}\n",
    "grid = GridSearchCV(estimator=rf, param_grid=params)\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred = grid.predict(x_test)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9995185131686648\n",
      "================================================\n",
      "Test Accuracy: 0.9100712497592913\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.91007542 0.90909091]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.07136864443611368\n",
      "================================================\n",
      "Weighted precision 0.909983472205731\n",
      "Weighted recall 0.9100712497592913\n",
      "Weighted f1-score 0.8711164578741785\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      4708\n",
      "           1       0.91      0.04      0.08       485\n",
      "\n",
      "    accuracy                           0.91      5193\n",
      "   macro avg       0.91      0.52      0.52      5193\n",
      "weighted avg       0.91      0.91      0.87      5193\n",
      "\n",
      "================================================\n",
      "[[4706    2]\n",
      " [ 465   20]]\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "params = {'n_estimators': [100], 'max_depth':[10], 'max_features':[100]}\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "train_score = rf.score(x_train, y_train)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>location_list</th>\n",
       "      <th>type_list</th>\n",
       "      <th>error_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>“少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25957</th>\n",
       "      <td>25957</td>\n",
       "      <td>对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25958</th>\n",
       "      <td>25958</td>\n",
       "      <td>学习汉语的乐处可真多。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25959</th>\n",
       "      <td>25959</td>\n",
       "      <td>在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25960</th>\n",
       "      <td>25960</td>\n",
       "      <td>和别人以汉语来交谈的亲切感等等。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25961</th>\n",
       "      <td>25961</td>\n",
       "      <td>(101F)(155J)\"}</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=590, end=604)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25962 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           sentence  \\\n",
       "0               0  [BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...   \n",
       "1               1  是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...   \n",
       "2               2                  “少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。   \n",
       "3               3          现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。   \n",
       "4               4                       但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？   \n",
       "...           ...                                                ...   \n",
       "25957       25957  对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...   \n",
       "25958       25958                                        学习汉语的乐处可真多。   \n",
       "25959       25959                   在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。   \n",
       "25960       25960                                   和别人以汉语来交谈的亲切感等等。   \n",
       "25961       25961                                     (101F)(155J)\"}   \n",
       "\n",
       "                                      location_list  type_list error_list  \n",
       "0         d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)          0          0  \n",
       "1       d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)          0          0  \n",
       "2      d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)          0          0  \n",
       "3      d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)          0          0  \n",
       "4      d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)          0          0  \n",
       "...                                             ...        ...        ...  \n",
       "25957  d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)          0          0  \n",
       "25958  d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)          0          0  \n",
       "25959  d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)          0          0  \n",
       "25960  d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)          0          0  \n",
       "25961  d.t.u.d.c.a.s.t.Sentence(begin=590, end=604)          0          0  \n",
       "\n",
       "[25962 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>location_list</th>\n",
       "      <th>type_list</th>\n",
       "      <th>error_list</th>\n",
       "      <th>WORDCUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>绿色绿色与饥饿如果要我在绿色食品与饥饿中做出选择的话我会毫不犹豫地的选择饥饿大家也应该在新闻...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>是的虽然科技在发展人们的需求也越来越多但是我认为与其将时间浪费在减少生产量来制造绿色食品还不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>“少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>少而精这正是绿色食品的特点也是那些吃饱撑着的人的观点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>现在普遍饮用的并不定绿色食品而是短文里所说的所谓吃了会有害于人体健康的食品</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>但是究竟有多少人是因为吃了这些食品而死亡生病的呢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25957</th>\n",
       "      <td>25957</td>\n",
       "      <td>对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>对于我来说学习汉语的苦是经历人为的障碍而不像其他的外国人因不是他们的母语而遇到了语言语文转换的困难</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25958</th>\n",
       "      <td>25958</td>\n",
       "      <td>学习汉语的乐处可真多。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>学习汉语的乐处可真多</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25959</th>\n",
       "      <td>25959</td>\n",
       "      <td>在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>在看国语电影时能了解电影剧情和对白而不需靠字幕和翻译</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25960</th>\n",
       "      <td>25960</td>\n",
       "      <td>和别人以汉语来交谈的亲切感等等。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>和别人以汉语来交谈的亲切感等等</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25961</th>\n",
       "      <td>25961</td>\n",
       "      <td>(101F)(155J)\"}</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=590, end=604)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25962 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           sentence  \\\n",
       "0               0  [BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...   \n",
       "1               1  是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...   \n",
       "2               2                  “少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。   \n",
       "3               3          现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。   \n",
       "4               4                       但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？   \n",
       "...           ...                                                ...   \n",
       "25957       25957  对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...   \n",
       "25958       25958                                        学习汉语的乐处可真多。   \n",
       "25959       25959                   在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。   \n",
       "25960       25960                                   和别人以汉语来交谈的亲切感等等。   \n",
       "25961       25961                                     (101F)(155J)\"}   \n",
       "\n",
       "                                      location_list  type_list error_list  \\\n",
       "0         d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)          0          0   \n",
       "1       d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)          0          0   \n",
       "2      d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)          0          0   \n",
       "3      d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)          0          0   \n",
       "4      d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)          0          0   \n",
       "...                                             ...        ...        ...   \n",
       "25957  d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)          0          0   \n",
       "25958  d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)          0          0   \n",
       "25959  d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)          0          0   \n",
       "25960  d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)          0          0   \n",
       "25961  d.t.u.d.c.a.s.t.Sentence(begin=590, end=604)          0          0   \n",
       "\n",
       "                                                 WORDCUT  \n",
       "0      绿色绿色与饥饿如果要我在绿色食品与饥饿中做出选择的话我会毫不犹豫地的选择饥饿大家也应该在新闻...  \n",
       "1      是的虽然科技在发展人们的需求也越来越多但是我认为与其将时间浪费在减少生产量来制造绿色食品还不...  \n",
       "2                             少而精这正是绿色食品的特点也是那些吃饱撑着的人的观点  \n",
       "3                  现在普遍饮用的并不定绿色食品而是短文里所说的所谓吃了会有害于人体健康的食品  \n",
       "4                               但是究竟有多少人是因为吃了这些食品而死亡生病的呢  \n",
       "...                                                  ...  \n",
       "25957  对于我来说学习汉语的苦是经历人为的障碍而不像其他的外国人因不是他们的母语而遇到了语言语文转换的困难  \n",
       "25958                                         学习汉语的乐处可真多  \n",
       "25959                         在看国语电影时能了解电影剧情和对白而不需靠字幕和翻译  \n",
       "25960                                    和别人以汉语来交谈的亲切感等等  \n",
       "25961                                                     \n",
       "\n",
       "[25962 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word cut\n",
    "import re\n",
    "import string\n",
    "df2 = pd.read_csv(r'C:\\Users\\dawns\\Desktop\\Master thesis\\data\\Error annotation dataset.csv')\n",
    "\n",
    "comp = re.compile('[^A-Z^a-z^0-9^ ]')\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation+'”“’�—…°'))\n",
    "pc = r\"\\d+\\.?\\d*\"\n",
    "\n",
    "df2['WORDCUT'] = df2['sentence']\n",
    "#去除字母数字表情和其它字符\n",
    "def clear_character(sentence):\n",
    "    pattern1='[a-zA-Z0-9]'\n",
    "    pattern2 = '\\[.*?\\]'\n",
    "    pattern3 = re.compile(u'[^\\s1234567890:：' + '\\u4e00-\\u9fa5]+')\n",
    "    pattern4='[’!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]+'\n",
    "    line1=re.sub(pattern1,'',sentence)   #去除英文字母和数字\n",
    "    line2=re.sub(pattern2,'',line1)   #去除表情\n",
    "    line3=re.sub(pattern3,'',line2)   #去除其它字符\n",
    "    line4=re.sub(pattern4, '', line3) #去掉残留的冒号及其它符号\n",
    "    new_sentence=''.join(line4.split()) #去除空白\n",
    "    return new_sentence\n",
    "    #return ' '.join(cw)\n",
    "df2['WORDCUT'] = df2['WORDCUT'].apply(clear_character)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(r'C:\\Users\\dawns\\Desktop\\Master thesis\\data\\Error annotation dataset(new).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>location_list</th>\n",
       "      <th>type_list</th>\n",
       "      <th>error_list</th>\n",
       "      <th>WORDCUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>绿色绿色与饥饿如果要我在绿色食品与饥饿中做出选择的话我会毫不犹豫地的选择饥饿大家也应该在新闻...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>是的虽然科技在发展人们的需求也越来越多但是我认为与其将时间浪费在减少生产量来制造绿色食品还不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>“少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>少而精这正是绿色食品的特点也是那些吃饱撑着的人的观点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>现在普遍饮用的并不定绿色食品而是短文里所说的所谓吃了会有害于人体健康的食品</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>但是究竟有多少人是因为吃了这些食品而死亡生病的呢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25956</th>\n",
       "      <td>25956</td>\n",
       "      <td>25956</td>\n",
       "      <td>庆幸的是我当时没有接受那位老师[F師]的劝[F勸]告。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=428, end=455)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>庆幸的是我当时没有接受那位老师的劝告</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25957</th>\n",
       "      <td>25957</td>\n",
       "      <td>25957</td>\n",
       "      <td>对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>对于我来说学习汉语的苦是经历人为的障碍而不像其他的外国人因不是他们的母语而遇到了语言语文转换的困难</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25958</th>\n",
       "      <td>25958</td>\n",
       "      <td>25958</td>\n",
       "      <td>学习汉语的乐处可真多。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>学习汉语的乐处可真多</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25959</th>\n",
       "      <td>25959</td>\n",
       "      <td>25959</td>\n",
       "      <td>在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>在看国语电影时能了解电影剧情和对白而不需靠字幕和翻译</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25960</th>\n",
       "      <td>25960</td>\n",
       "      <td>25960</td>\n",
       "      <td>和别人以汉语来交谈的亲切感等等。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>和别人以汉语来交谈的亲切感等等</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24530 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                 0           0   \n",
       "1                 1           1   \n",
       "2                 2           2   \n",
       "3                 3           3   \n",
       "4                 4           4   \n",
       "...             ...         ...   \n",
       "25956         25956       25956   \n",
       "25957         25957       25957   \n",
       "25958         25958       25958   \n",
       "25959         25959       25959   \n",
       "25960         25960       25960   \n",
       "\n",
       "                                                sentence  \\\n",
       "0      [BD《]绿色绿色与饥饿[BD》]如果要我在绿色食品与饥饿{CQ中}做出选择的话，我会毫不犹...   \n",
       "1      是的[BQ，]虽然科技在发展，人们的需求也越来越多，但是我认为，与其将时间浪费在减少生产量来...   \n",
       "2                      “少而精”，这正是绿色食品的特点，也是那些“吃饱撑着”的人的观点。   \n",
       "3              现在普遍饮用的并不定绿色食品，而是短文里所说的所谓“吃了会有害于人体健康”的食品。   \n",
       "4                           但是，究竟有多少人是因为吃了这些食品而死亡（生病）的呢？   \n",
       "...                                                  ...   \n",
       "25956                        庆幸的是我当时没有接受那位老师[F師]的劝[F勸]告。   \n",
       "25957  对于我来说[F説][BQ，]学习汉语的苦[B告]是经历人为的障碍[F礙]，而不像其他的外国人...   \n",
       "25958                                        学习汉语的乐处可真多。   \n",
       "25959                   在看国语电影时[F時]，能了解电影剧情和对白而不需靠字幕和翻译。   \n",
       "25960                                   和别人以汉语来交谈的亲切感等等。   \n",
       "\n",
       "                                      location_list  type_list error_list  \\\n",
       "0         d.t.u.d.c.a.s.t.Sentence(begin=0, end=98)          0          0   \n",
       "1       d.t.u.d.c.a.s.t.Sentence(begin=98, end=178)          0          0   \n",
       "2      d.t.u.d.c.a.s.t.Sentence(begin=178, end=211)          0          0   \n",
       "3      d.t.u.d.c.a.s.t.Sentence(begin=211, end=252)          0          0   \n",
       "4      d.t.u.d.c.a.s.t.Sentence(begin=252, end=280)          0          0   \n",
       "...                                             ...        ...        ...   \n",
       "25956  d.t.u.d.c.a.s.t.Sentence(begin=428, end=455)          0          0   \n",
       "25957  d.t.u.d.c.a.s.t.Sentence(begin=455, end=531)          0          0   \n",
       "25958  d.t.u.d.c.a.s.t.Sentence(begin=531, end=542)          0          0   \n",
       "25959  d.t.u.d.c.a.s.t.Sentence(begin=542, end=574)          0          0   \n",
       "25960  d.t.u.d.c.a.s.t.Sentence(begin=574, end=590)          0          0   \n",
       "\n",
       "                                                 WORDCUT  \n",
       "0      绿色绿色与饥饿如果要我在绿色食品与饥饿中做出选择的话我会毫不犹豫地的选择饥饿大家也应该在新闻...  \n",
       "1      是的虽然科技在发展人们的需求也越来越多但是我认为与其将时间浪费在减少生产量来制造绿色食品还不...  \n",
       "2                             少而精这正是绿色食品的特点也是那些吃饱撑着的人的观点  \n",
       "3                  现在普遍饮用的并不定绿色食品而是短文里所说的所谓吃了会有害于人体健康的食品  \n",
       "4                               但是究竟有多少人是因为吃了这些食品而死亡生病的呢  \n",
       "...                                                  ...  \n",
       "25956                                 庆幸的是我当时没有接受那位老师的劝告  \n",
       "25957  对于我来说学习汉语的苦是经历人为的障碍而不像其他的外国人因不是他们的母语而遇到了语言语文转换的困难  \n",
       "25958                                         学习汉语的乐处可真多  \n",
       "25959                         在看国语电影时能了解电影剧情和对白而不需靠字幕和翻译  \n",
       "25960                                    和别人以汉语来交谈的亲切感等等  \n",
       "\n",
       "[24530 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove sentence without contents\n",
    "df1 = pd.read_csv(r'C:\\Users\\dawns\\Desktop\\Master thesis\\data\\Error annotation dataset(new).csv')\n",
    "df1.dropna(axis=0, how='any', inplace=True)\n",
    "df1\n",
    "# delete 1432 sentence without any content, those sentence only contain numbers or punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22105\n",
      "1     2425\n",
      "Name: type_list, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = df1.loc[:, 'type_list'].value_counts()\n",
    "count\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠采样\n",
    "\n",
    "df3=df1[df1[\"type_list\"]==1]#正样本部分\n",
    "df0=df1[df1[\"type_list\"]==0]#负样本部分\n",
    "df4=df0.sample(frac=0.2)\n",
    "df_new=pd.concat([df3,df4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>location_list</th>\n",
       "      <th>type_list</th>\n",
       "      <th>error_list</th>\n",
       "      <th>WORDCUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>例如：任何豪华的建筑，一开始建造时，都先{CJX}需要打地基[BQ，]就是所谓“基础”，只有...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=453, end=510)</td>\n",
       "      <td>1</td>\n",
       "      <td>都先{CJX}</td>\n",
       "      <td>例如：任何豪华的建筑一开始建造时都先需要打地基就是所谓基础只有基础打好了才能提高</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>还有一种就是将科技再进一步提高，研制出既[B即]不影响人体健康，也不会影响生产量的农药，再将...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=582, end=652)</td>\n",
       "      <td>1</td>\n",
       "      <td>[B即]</td>\n",
       "      <td>还有一种就是将科技再进一步提高研制出既不影响人体健康也不会影响生产量的农药再将其普及化给人类...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>没有挨过饿的人是不会理解挨饿的痛苦的，所[C]以在先进国家也只有很少的人为这些挨饿的人{CD...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=219, end=281)</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD而}</td>\n",
       "      <td>没有挨过饿的人是不会理解挨饿的痛苦的所以在先进国家也只有很少的人为这些挨饿的人而去努力活动</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>现在世界上的饥饿问题也不亚于环境问题，因此有的人对于{CC由于}{CJ-zhuy人们}缺少粮...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=108, end=189)</td>\n",
       "      <td>1</td>\n",
       "      <td>{CC由于}{</td>\n",
       "      <td>现在世界上的饥饿问题也不亚于环境问题因此有的人对于由于人们缺少粮食而挨饿的问题而提出先提高该...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>如果每天吃{CD了}用化肥和农药的农作物{CQ就}不能{CC会}健康地生活{CD着}。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=322, end=365)</td>\n",
       "      <td>1</td>\n",
       "      <td>{CQ就}</td>\n",
       "      <td>如果每天吃了用化肥和农药的农作物就不能会健康地生活着</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016</th>\n",
       "      <td>6016</td>\n",
       "      <td>6016</td>\n",
       "      <td>[BC.]没有别的[C]办法了。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=355, end=371)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>没有别的办法了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22302</th>\n",
       "      <td>22302</td>\n",
       "      <td>22302</td>\n",
       "      <td>对于这个问题，我想首先[BD，]不同的国家会有不同的理解。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=13, end=42)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>对于这个问题我想首先不同的国家会有不同的理解</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>发达国家应该帮助{CJ-by他们}，提供技术。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=563, end=586)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>发达国家应该帮助他们提供技术</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13687</th>\n",
       "      <td>13687</td>\n",
       "      <td>13687</td>\n",
       "      <td>论学业，虽然不是个顶尖人物，却也是个不错的人才。</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=32, end=56)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>论学业虽然不是个顶尖人物却也是个不错的人才</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>12177</td>\n",
       "      <td>12177</td>\n",
       "      <td>[BC，]一般来说，他们需要{CC2需}这种人员[BQ,]因为对他们来说有好处，可以替他们来...</td>\n",
       "      <td>d.t.u.d.c.a.s.t.Sentence(begin=379, end=438)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>一般来说他们需要需这种人员因为对他们来说有好处可以替他们来做谈判生意</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6846 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  \\\n",
       "12               12          12   \n",
       "14               14          14   \n",
       "24               24          24   \n",
       "33               33          33   \n",
       "57               57          57   \n",
       "...             ...         ...   \n",
       "6016           6016        6016   \n",
       "22302         22302       22302   \n",
       "405             405         405   \n",
       "13687         13687       13687   \n",
       "12177         12177       12177   \n",
       "\n",
       "                                                sentence  \\\n",
       "12     例如：任何豪华的建筑，一开始建造时，都先{CJX}需要打地基[BQ，]就是所谓“基础”，只有...   \n",
       "14     还有一种就是将科技再进一步提高，研制出既[B即]不影响人体健康，也不会影响生产量的农药，再将...   \n",
       "24     没有挨过饿的人是不会理解挨饿的痛苦的，所[C]以在先进国家也只有很少的人为这些挨饿的人{CD...   \n",
       "33     现在世界上的饥饿问题也不亚于环境问题，因此有的人对于{CC由于}{CJ-zhuy人们}缺少粮...   \n",
       "57           如果每天吃{CD了}用化肥和农药的农作物{CQ就}不能{CC会}健康地生活{CD着}。   \n",
       "...                                                  ...   \n",
       "6016                                    [BC.]没有别的[C]办法了。   \n",
       "22302                      对于这个问题，我想首先[BD，]不同的国家会有不同的理解。   \n",
       "405                              发达国家应该帮助{CJ-by他们}，提供技术。   \n",
       "13687                           论学业，虽然不是个顶尖人物，却也是个不错的人才。   \n",
       "12177  [BC，]一般来说，他们需要{CC2需}这种人员[BQ,]因为对他们来说有好处，可以替他们来...   \n",
       "\n",
       "                                      location_list  type_list error_list  \\\n",
       "12     d.t.u.d.c.a.s.t.Sentence(begin=453, end=510)          1    都先{CJX}   \n",
       "14     d.t.u.d.c.a.s.t.Sentence(begin=582, end=652)          1       [B即]   \n",
       "24     d.t.u.d.c.a.s.t.Sentence(begin=219, end=281)          1      {CD而}   \n",
       "33     d.t.u.d.c.a.s.t.Sentence(begin=108, end=189)          1    {CC由于}{   \n",
       "57     d.t.u.d.c.a.s.t.Sentence(begin=322, end=365)          1      {CQ就}   \n",
       "...                                             ...        ...        ...   \n",
       "6016   d.t.u.d.c.a.s.t.Sentence(begin=355, end=371)          0          0   \n",
       "22302    d.t.u.d.c.a.s.t.Sentence(begin=13, end=42)          0          0   \n",
       "405    d.t.u.d.c.a.s.t.Sentence(begin=563, end=586)          0          0   \n",
       "13687    d.t.u.d.c.a.s.t.Sentence(begin=32, end=56)          0          0   \n",
       "12177  d.t.u.d.c.a.s.t.Sentence(begin=379, end=438)          0          0   \n",
       "\n",
       "                                                 WORDCUT  \n",
       "12              例如：任何豪华的建筑一开始建造时都先需要打地基就是所谓基础只有基础打好了才能提高  \n",
       "14     还有一种就是将科技再进一步提高研制出既不影响人体健康也不会影响生产量的农药再将其普及化给人类...  \n",
       "24         没有挨过饿的人是不会理解挨饿的痛苦的所以在先进国家也只有很少的人为这些挨饿的人而去努力活动  \n",
       "33     现在世界上的饥饿问题也不亚于环境问题因此有的人对于由于人们缺少粮食而挨饿的问题而提出先提高该...  \n",
       "57                            如果每天吃了用化肥和农药的农作物就不能会健康地生活着  \n",
       "...                                                  ...  \n",
       "6016                                             没有别的办法了  \n",
       "22302                             对于这个问题我想首先不同的国家会有不同的理解  \n",
       "405                                       发达国家应该帮助他们提供技术  \n",
       "13687                              论学业虽然不是个顶尖人物却也是个不错的人才  \n",
       "12177                 一般来说他们需要需这种人员因为对他们来说有好处可以替他们来做谈判生意  \n",
       "\n",
       "[6846 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_new['WORDCUT'], df_new['type_list'], test_size=0.2)\n",
    "x_train = x_train.apply(lambda x: preprocessing_sentence(x))\n",
    "x_test = x_test.apply(lambda x: preprocessing_sentence(x))\n",
    "\n",
    "\n",
    "\n",
    "#TF-IDF\n",
    "tf = TfidfVectorizer()\n",
    "x_train = tf.fit_transform(x_train).toarray()\n",
    "x_test = tf.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7753834915997078\n",
      "================================================\n",
      "Test Accuracy: 0.6912408759124088\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.7092511  0.60425532]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.22395714763977237\n",
      "================================================\n",
      "Weighted precision 0.6730773719891109\n",
      "Weighted recall 0.6912408759124088\n",
      "Weighted f1-score 0.6574869041919021\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       898\n",
      "           1       0.60      0.30      0.40       472\n",
      "\n",
      "    accuracy                           0.69      1370\n",
      "   macro avg       0.66      0.60      0.60      1370\n",
      "weighted avg       0.67      0.69      0.66      1370\n",
      "\n",
      "================================================\n",
      "[[805  93]\n",
      " [330 142]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "train_score = lr.score(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "y_pred = lr.predict(x_test)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([2.12407684, 1.84209514, 1.94527745, 1.93135524, 1.81014657]), 'score_time': array([0.01854825, 0.01800227, 0.01633382, 0.01760387, 0.01823878]), 'test_recall': array([0.25319693, 0.23529412, 0.27621483, 0.25384615, 0.24871795]), 'test_qwkappa': array([0.19368309, 0.17718562, 0.25820367, 0.18218801, 0.19765018])}\n",
      "Mean recall: 0.25345399698340876\n",
      "Mean qwkappa: 0.20178211271444485\n"
     ]
    }
   ],
   "source": [
    "scoring = {'recall': 'recall','qwkappa': make_scorer(cohen_kappa_score,weights='quadratic')}\n",
    "scores = cross_validate(lr, x_train, y_train, cv=5, scoring=scoring)#5-fold cv\n",
    "recall = scores['test_recall']\n",
    "qwkappa = scores['test_qwkappa']\n",
    "print(scores)\n",
    "print('Mean recall:',recall.mean())\n",
    "print('Mean qwkappa:',qwkappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9475894813732652\n",
      "================================================\n",
      "Test Accuracy: 0.6992700729927007\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.70320405 0.67391304]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.22576786752844868\n",
      "================================================\n",
      "Weighted precision 0.6930270269402418\n",
      "Weighted recall 0.6992700729927007\n",
      "Weighted f1-score 0.6538538954962313\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = OneVsRestClassifier(svm.SVC(kernel='rbf',gamma='scale'))#linear\n",
    "clt = model.fit(x_train,y_train)\n",
    "y_pred = clt.predict(x_test)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "train_score = clt.score(x_train, y_train)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8011322132943755\n",
      "================================================\n",
      "Test Accuracy: 0.6839416058394161\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.67874794 0.72435897]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.20469932725025275\n",
      "================================================\n",
      "Weighted precision 0.6954941815200477\n",
      "Weighted recall 0.6839416058394161\n",
      "Weighted f1-score 0.6270813368458579\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.95      0.79       867\n",
      "           1       0.72      0.22      0.34       503\n",
      "\n",
      "    accuracy                           0.68      1370\n",
      "   macro avg       0.70      0.59      0.57      1370\n",
      "weighted avg       0.70      0.68      0.63      1370\n",
      "\n",
      "================================================\n",
      "[[824  43]\n",
      " [390 113]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "NB = BernoulliNB()\n",
    "NB.fit(x_train, y_train)\n",
    "y_pred = NB.predict(x_test)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "train_score = NB.score(x_train, y_train)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9994521548575602\n",
      "================================================\n",
      "Test Accuracy: 0.6846715328467153\n",
      "================================================\n",
      "acc_for_each_class:\n",
      " [0.69230769 0.63218391]\n",
      "================================================\n",
      "qwkappa:\n",
      " 0.18579824349012797\n",
      "================================================\n",
      "Weighted precision 0.6713301967769625\n",
      "Weighted recall 0.6846715328467153\n",
      "Weighted f1-score 0.6341143207447818\n",
      "================================================\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.93      0.79       892\n",
      "           1       0.63      0.23      0.34       478\n",
      "\n",
      "    accuracy                           0.68      1370\n",
      "   macro avg       0.66      0.58      0.57      1370\n",
      "weighted avg       0.67      0.68      0.63      1370\n",
      "\n",
      "================================================\n",
      "[[828  64]\n",
      " [368 110]]\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "params = {'n_estimators': [100], 'max_depth':[10], 'max_features':[100]}\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "train_score = rf.score(x_train, y_train)\n",
    "test_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Train Accuracy:\", train_score)\n",
    "print(\"================================================\")\n",
    "print(\"Test Accuracy:\", test_score)\n",
    "print(\"================================================\")\n",
    "acc_for_each_class = metrics.precision_score(y_test,y_pred,average=None)\n",
    "print(\"acc_for_each_class:\\n\",acc_for_each_class)\n",
    "print(\"================================================\")\n",
    "qwkappa = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
    "print(\"qwkappa:\\n\",qwkappa)\n",
    "print(\"================================================\")\n",
    "print('Weighted precision', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"================================================\")\n",
    "classification_rep = classification_report(y_test,y_pred)\n",
    "print(\"classification report: \\n\",classification_rep)\n",
    "print(\"================================================\")\n",
    "confusion_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
